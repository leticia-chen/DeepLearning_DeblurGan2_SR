{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOU9A6ZGCfOHL6UOSolgfFF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leticia-chen/DeepLearning_DeblurGan2_SR/blob/main/DeblurGanv2_SR_for_stanCode.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LWoNZ_SBwELJ"
      },
      "outputs": [],
      "source": [
        "# this mounts your Google Drive to the Colab VM.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 請輸入資料夾之所在位置\n",
        "FOLDERNAME = 'Colab\\ Notebooks/DeblurGanv2-SR'\n",
        "assert FOLDERNAME is not None, \"[!] Enter the foldername.\""
      ],
      "metadata": {
        "id": "LcXnjmVj4f-s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# now that we've mounted your Drive, this ensures that\n",
        "# the Python interpreter of the Colab VM can load\n",
        "# python files from within it.\n",
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/{}'.format(FOLDERNAME))"
      ],
      "metadata": {
        "id": "agGzyQEAdle2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %pwd 显示当前工作目录\n",
        "# %cd 改变当前工作目录"
      ],
      "metadata": {
        "id": "7vCrzb6ZwsTk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get to the folder we are at\n",
        "%cd drive/MyDrive/$FOLDERNAME/"
      ],
      "metadata": {
        "id": "S55syBAAdrSD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "print('using device:', device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fCmjYycxdsXr",
        "outputId": "04c72c7c-3397-4f36-a9cf-1c32f7730056"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if hasattr(torch.cuda, 'empty_cache'):\n",
        "    torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "NOQ5gEPwdyId"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%ls"
      ],
      "metadata": {
        "id": "VSS06gFmnA77"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 查数量\n",
        "import os\n",
        "\n",
        "folders = os.listdir('./GOPRO_Large/train')\n",
        "print(folders)\n",
        "folders = os.listdir('./GOPRO_Large/test')\n",
        "print(folders)"
      ],
      "metadata": {
        "id": "2vu5YhI-AkXr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for folder in folders:\n",
        "  blur_sharp_folders = os.path.join('./GOPRO_Large/train', folder)\n",
        "  blur_sharp_folders = os.path.join('./GOPRO_Large/test', folder)\n",
        "  print(blur_sharp_folders)"
      ],
      "metadata": {
        "id": "6qe4EeEYWfBh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "blur_files = os.listdir('./DeblurGANv2/submit')\n",
        "print('blured:', len(blur_files))\n",
        "sharp_files = os.listdir('./GOPRO_Large/train/sharp')\n",
        "print('sharp:', len(sharp_files))\n",
        "test_blur_files = os.listdir('./DeblurGANv2/submit_test')\n",
        "print('blured:', len(test_blur_files))\n",
        "test_sharp_files = os.listdir('./GOPRO_Large/test/sharp')\n",
        "print('sharp:', len(test_sharp_files))"
      ],
      "metadata": {
        "id": "FkPaG-RQYElX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2bd20712-b613-4fe3-fdbf-f65eea2b5a3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "blured: 2103\n",
            "sharp: 2103\n",
            "blured: 1111\n",
            "sharp: 1111\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Building Dataset"
      ],
      "metadata": {
        "id": "Iw4AEGxdMVoI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "mean = np.array([0.485, 0.456, 0.406])\n",
        "std = np.array([0.229, 0.224, 0.225])\n",
        "\n",
        "class GoproDataset(Dataset):\n",
        "  def __init__(self, root, submit, hr_shape):\n",
        "    # hr=high resolution, lr=low resolution\n",
        "    hr_height, hr_width = hr_shape                     \n",
        "\n",
        "    self.lr_transform = transforms.Compose([\n",
        "            transforms.Resize((hr_height // 4, hr_width // 4), Image.BICUBIC),     \n",
        "            transforms.ToTensor(),                                                  # channel, H, W\n",
        "            transforms.Normalize(mean, std)])\n",
        "    \n",
        "    self.hr_transform = transforms.Compose([\n",
        "            transforms.Resize((hr_height, hr_width), Image.BICUBIC),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean, std)])\n",
        "    \n",
        "    self.sharp_file_paths = []\n",
        "\n",
        "    sub_folders = os.listdir(root)                                                  # blur, sharp\n",
        "\n",
        "    for folder_name in sub_folders:\n",
        "      if folder_name == 'sharp':\n",
        "        sharp_sub_folder = os.path.join(root, folder_name)\n",
        "        print(sharp_sub_folder)\n",
        "        sharp_file_names = os.listdir(sharp_sub_folder)                             # img´s files name\n",
        "\n",
        "        for file_name in sharp_file_names:\n",
        "          sharp_file_path = os.path.join(sharp_sub_folder, file_name)\n",
        "          self.sharp_file_paths.append(sharp_file_path)\n",
        "          self.sharp_file_paths.sort()\n",
        "    # print('sharp:', self.sharp_file_paths[:10])\n",
        "    # print('3 last:', self.sharp_file_paths[2100:])\n",
        "\n",
        "    self.blur_file_paths = []\n",
        "\n",
        "    for file_name in os.listdir(submit):\n",
        "      blur_file_path = os.path.join(submit, file_name)\n",
        "      self.blur_file_paths.append(blur_file_path)\n",
        "      self.blur_file_paths.sort()\n",
        "    # print('blur:', self.blur_file_paths[:10])\n",
        "    # print('3 last:', self.blur_file_paths[2100:])\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "\n",
        "      sharp_file_path = self.sharp_file_paths[index % len(self.sharp_file_paths)]\n",
        "      blur_file_path = self.blur_file_paths[index % len(self.blur_file_paths)]\n",
        "\n",
        "      blur_img = Image.open(blur_file_path).convert('RGB')             \n",
        "      sharp_img = Image.open(sharp_file_path).convert('RGB')\n",
        "\n",
        "      img_lr = self.lr_transform(blur_img)                             \n",
        "      img_hr = self.hr_transform(sharp_img)\n",
        "\n",
        "      return {\"blur\": img_lr, \"sharp\": img_hr}                         \n",
        "\n",
        "  # 定义dataloader和每次读取图像时均调用\n",
        "  def __len__(self):\n",
        "      return len(self.sharp_file_paths)\n"
      ],
      "metadata": {
        "id": "hQeF2snDDowx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Load\n"
      ],
      "metadata": {
        "id": "42OH9fufeWb7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# train 的 blur 照片在 DeblurGANv2/submit\n",
        "train_path = 'GOPRO_Large/train'                                               \n",
        "deblurred_path = 'DeblurGANv2/submit'\n",
        "test_path = 'GOPRO_Large/test'\n",
        "deblurred_test_path = 'DeblurGANv2/submit_test'\n",
        "\n",
        "train = False\n",
        "\n",
        "if train:\n",
        "  mini_train = (DataLoader(GoproDataset(train_path, deblurred_path, (288, 512)),\n",
        "                          batch_size=5, shuffle=True))\n",
        "else:\n",
        "  mini_test = (DataLoader(GoproDataset(test_path, deblurred_test_path, (720, 1280)),\n",
        "                          batch_size=5, shuffle=True))\n",
        "\n",
        "mini_train_shape = next(iter(mini_test))"
      ],
      "metadata": {
        "id": "ttCOo3FWe4x7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(mini_train_shape['blur'].shape)\n",
        "print(mini_train_shape['sharp'].shape)"
      ],
      "metadata": {
        "id": "LfuLRYumA4T2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d78e83f-5932-4718-d6aa-e26e328b7ac8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([5, 3, 180, 320])\n",
            "torch.Size([5, 3, 720, 1280])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generator: Residual block, Upsample block, Generator net"
      ],
      "metadata": {
        "id": "iIItgD9XBMix"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "\n",
        "class ResidualBlock(nn.Module):\n",
        "  def __init__(self, channels):                                 \n",
        "    super(ResidualBlock, self).__init__()\n",
        "    # in_channel X out_channel X kernel X padding\n",
        "    # channels = 64                                                   \n",
        "    self.conv1 = nn.Conv2d(channels, channels, kernel_size=3, padding=1)\n",
        "    self.bn1 = nn.BatchNorm2d(channels, 0.8)                          \n",
        "    self.prelu = nn.PReLU(channels)\n",
        "    self.conv2 = nn.Conv2d(channels, channels, kernel_size=3, padding=1)\n",
        "    self.bn2 = nn.BatchNorm2d(channels, 0.8)\n",
        "\n",
        "  def forward(self, x):\n",
        "    short_cut = x\n",
        "    x = self.conv1(x)\n",
        "    x = self.bn1(x)\n",
        "    x = self.prelu(x)\n",
        "    x = self.conv2(x)\n",
        "    x = self.bn2(x)\n",
        "\n",
        "    return x + short_cut"
      ],
      "metadata": {
        "id": "MqyA0ykbe3T7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class UpsampleBlock(nn.Module):\n",
        "  def __init__(self, in_channels, up_scale):                           \n",
        "    super(UpsampleBlock, self).__init__()\n",
        "    self.conv = nn.Conv2d(in_channels, in_channels*up_scale**2, kernel_size=3, padding=1)      # 64->256\n",
        "    self.pixel_suffle = nn.PixelShuffle(up_scale)\n",
        "    self.prelu = nn.PReLU(in_channels)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv(x)\n",
        "    x = self.pixel_suffle(x)\n",
        "    x = self.prelu(x)\n",
        "    return(x)\n"
      ],
      "metadata": {
        "id": "ZvPjkkUWedoR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NetG(nn.Module):\n",
        "  def __init__(self, num_residual=16):                            \n",
        "\n",
        "    super(NetG, self).__init__()\n",
        "\n",
        "    # First layer\n",
        "    self.conv1 = nn.Sequential(\n",
        "        nn.Conv2d(3, 64, kernel_size=9, padding=4),                 \n",
        "        nn.PReLU(64)\n",
        "    )\n",
        "\n",
        "    # Residual blocks\n",
        "    self.res_blocks = []\n",
        "    for _ in range(num_residual):\n",
        "      self.res_blocks.append(ResidualBlock(64))\n",
        "    self.res_blocks = nn.Sequential(*self.res_blocks)\n",
        "\n",
        "    # Second conv layer pos residual\n",
        "    self.conv2 = nn.Sequential(\n",
        "        nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
        "        nn.BatchNorm2d(64, 0.8)\n",
        "    )\n",
        "\n",
        "    # Upsampling layer\n",
        "    self.upsample = []\n",
        "    for _ in range(2):\n",
        "      self.upsample.append(UpsampleBlock(64, 2))\n",
        "    self.upsample = nn.Sequential(*self.upsample)\n",
        "\n",
        "    # the last conv layer\n",
        "    self.conv3 = nn.Sequential(\n",
        "        nn.Conv2d(64, 3, kernel_size=9, stride= 1, padding=4),\n",
        "        nn.Tanh())\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv1(x)\n",
        "    short_cut = x\n",
        "    x = self.res_blocks(x)\n",
        "    x = self.conv2(x)\n",
        "    x = x + short_cut\n",
        "    x = self.upsample(x)\n",
        "    out = self.conv3(x)\n",
        "\n",
        "    return out\n"
      ],
      "metadata": {
        "id": "IKlVCDU7zE-m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Discriminator"
      ],
      "metadata": {
        "id": "sdmZNVHKlwoQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NetD(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(NetD, self).__init__()\n",
        "    self.d_net = nn.Sequential(\n",
        "        nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
        "        nn.LeakyReLU(0.2),\n",
        "\n",
        "        nn.Conv2d(64, 64, kernel_size=3, stride=2, padding=1),\n",
        "        nn.BatchNorm2d(64),\n",
        "        nn.LeakyReLU(0.2),\n",
        "\n",
        "        nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "        nn.BatchNorm2d(128),\n",
        "        nn.LeakyReLU(0.2),\n",
        "\n",
        "        nn.Conv2d(128, 128, kernel_size=3, stride=2, padding=1),\n",
        "        nn.BatchNorm2d(128),\n",
        "        nn.LeakyReLU(0.2),\n",
        "\n",
        "        nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
        "        nn.BatchNorm2d(256),\n",
        "        nn.LeakyReLU(0.2),\n",
        "\n",
        "        nn.Conv2d(256, 256, kernel_size=3, stride=2, padding=1),\n",
        "        nn.BatchNorm2d(256),\n",
        "        nn.LeakyReLU(0.2),\n",
        "\n",
        "        nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
        "        nn.BatchNorm2d(512),\n",
        "        nn.LeakyReLU(0.2),\n",
        "\n",
        "        nn.Conv2d(512, 512, kernel_size=3, stride=2, padding=1),\n",
        "        nn.BatchNorm2d(512),\n",
        "        nn.LeakyReLU(0.2),\n",
        "\n",
        "        # AdaptiveAvgPool2d 可将图像最后调整成自己要的 (H,W)\n",
        "        nn.AdaptiveAvgPool2d(1),                        \n",
        "        nn.Conv2d(512, 1024, kernel_size=1),\n",
        "        nn.LeakyReLU(0.2),\n",
        "        nn.Conv2d(1024, 1, kernel_size=1)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    batch_size = x.size(0)                \n",
        "    return torch.sigmoid(self.d_net(x).view(batch_size))\n"
      ],
      "metadata": {
        "id": "z0DXPOJGgUXt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load vgg19 pretrained model"
      ],
      "metadata": {
        "id": "fcmmufbKQxw0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extractor 'vgg19': 'https://download.pytorch.org/models/vgg19-dcbb9e9d.pth'"
      ],
      "metadata": {
        "id": "H4xo32F0Okdi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.models import vgg19\n",
        "\n",
        "class FeatureExtractor(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(FeatureExtractor, self).__init__()\n",
        "        vgg19_model = vgg19(pretrained=True)\n",
        "        self.feature_extractor = nn.Sequential(*list(vgg19_model.features.children())[:18])\n",
        "\n",
        "    def forward(self, img):\n",
        "        return self.feature_extractor(img)\n",
        "        "
      ],
      "metadata": {
        "id": "ZLIy2yzAjFy0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inicialization"
      ],
      "metadata": {
        "id": "qRBBP5Rd0xNq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "netG = NetG().cuda()\n",
        "netD = NetD().cuda()\n",
        "feature_extractor = FeatureExtractor().cuda()\n",
        "feature_extractor.eval()"
      ],
      "metadata": {
        "id": "2Ui6fLgZ0KXR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define Optimizers and LOSS"
      ],
      "metadata": {
        "id": "MzkU9e9Z13h_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 0.00008\n",
        "betas = (0.5, 0.999)\n",
        "\n",
        "d_optimizer = torch.optim.Adam(netD.parameters(), lr=lr, betas=betas)\n",
        "g_optimizer = torch.optim.Adam(netG.parameters(), lr=lr, betas=betas)"
      ],
      "metadata": {
        "id": "8e1EaZTp0KMn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mes_loss = torch.nn.MSELoss().to(device)\n",
        "l1_loss = torch.nn.L1Loss().to(device)\n",
        "\n",
        "def discriminator_loss(real_output, fake_output1):                            # discriminator 的 output 是 sigmoid, 机率，这里是一个 batch 单位\n",
        "  real_loss = mes_loss(real_output, torch.ones_like(real_output))             # 产生与 given tensor 一样的 shape,但 elements 全为 1 的 tensor\n",
        "  fake_loss = mes_loss(fake_output1, torch.zeros_like(fake_output1))          # 与 fake 的 label 比\n",
        "  return (real_loss + fake_loss)/2\n",
        "\n",
        "def generator_loss(fake_output2):\n",
        "  return mes_loss(fake_output2, torch.ones_like(fake_output2))"
      ],
      "metadata": {
        "id": "iuViU1Zl-Ew3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model-checkpoint"
      ],
      "metadata": {
        "id": "npQGgxfeRUjL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def model_checkpoint(filename):\n",
        "  generator_file_paths = []\n",
        "  discriminator_file_paths = []\n",
        "\n",
        "  files = os.listdir(filename)                                  # blur, sharp\n",
        "  # print(len(files))\n",
        "  # print('files:', files)\n",
        "  # print(files[0], files[1], files[64], files[65])\n",
        "\n",
        "  for file in files:\n",
        "    if file[0] == 'g':\n",
        "      generator_file = os.path.join(filename, file)\n",
        "      generator_file_paths.append(generator_file)\n",
        "      generator_file_paths.sort()\n",
        "    else:\n",
        "      discriminator_file = os.path.join(filename, file)\n",
        "      discriminator_file_paths.append(discriminator_file)\n",
        "      discriminator_file_paths.sort()\n",
        "\n",
        "  return generator_file_paths, discriminator_file_paths  "
      ],
      "metadata": {
        "id": "9wdVDEu7XS41"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "PSNR Function"
      ],
      "metadata": {
        "id": "RzNFiNC0Xzyh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import math\n",
        "\n",
        "def PSNR(imgs1, imgs2):\n",
        "\n",
        "  total_p = 0\n",
        "  total_s = 0\n",
        "\n",
        "  for i in range(len(imgs1)):\n",
        "\n",
        "    mse = torch.mean((imgs1[i] / 255. - imgs2[i] / 255.) ** 2)\n",
        "\n",
        "    if mse == 0:\n",
        "      p = 100\n",
        "    else:\n",
        "      PIXEL_MAX = 1\n",
        "      p = 20 * math.log10(PIXEL_MAX / math.sqrt(mse))\n",
        "    \n",
        "    total_p += p\n",
        "    # total_s += s\n",
        "\n",
        "  avg_p = total_p/len(imgs1)\n",
        "  avg_s = total_s/len(imgs2)\n",
        "    \n",
        "  return avg_p, avg_s"
      ],
      "metadata": {
        "id": "d1Q0eHb_XXSF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def design(title, lst1, lst2, label1, label2, xlabel, ylabel, mum):\n",
        "  plt.figure(figsize=(6,4))                         # 图表大小\n",
        "  plt.title(str(title))                             # 图表名称\n",
        "  plt.plot(lst1,label=str(label1))                  # 画出线条，label 是线条名称\n",
        "  plt.plot(lst2,label=str(label2))\n",
        "  plt.xlabel(str(xlabel))                           # x 轴名称\n",
        "  plt.ylabel(str(ylabel))                           # y 轴名称\n",
        "  plt.xticks(ticks=np.arange(len(lst1)), labels=np.arange(1, len(lst1)+1))   # 刻度\n",
        "  plt.legend()\n",
        "   # save 是 plt.savefig('档名', bbox_inches=`tight`)->将图表多余的空白区域裁减掉\n",
        "  plt.savefig(f'matplotlib/{title}.png', bbox_inches='tight')\n",
        "  plt.subplot(33, 2, num)\n",
        "  plt.show() "
      ],
      "metadata": {
        "id": "xgtdi8jaXgPh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define Train or Test model"
      ],
      "metadata": {
        "id": "6mbnmKj35bOA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = False\n",
        "test = True"
      ],
      "metadata": {
        "id": "erMxhanZ5aqI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training"
      ],
      "metadata": {
        "id": "OgAAlXLgrfnX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.autograd import Variable\n",
        "import sys\n",
        "import itertools\n",
        "from torchvision.utils import save_image, make_grid\n",
        "from PIL import Image\n",
        "import time\n",
        "from torchvision.io import read_image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "dEcGG3l8wxHd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d_losses_0106 = []\n",
        "g_losses_0106 = []"
      ],
      "metadata": {
        "id": "tebdK5wdhogx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cuda = torch.cuda.is_available()\n",
        "Tensor = torch.cuda.FloatTensor if cuda else torch.Tensor\n",
        "\n",
        "num_epochs = 100            # 100\n",
        "num_epochs_test = 1\n",
        "checkpoint_interval = 5     # 10\n",
        "num_iters = 100             # 200\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "if train:\n",
        "\n",
        "  for epoch in range(num_epochs):  \n",
        "    \n",
        "    loss_dis, loss_gen = 0, 0\n",
        "\n",
        "    for i, imgs in enumerate(mini_train):\n",
        "      \n",
        "      netD.train()\n",
        "      netG.train()\n",
        "     \n",
        "      imgs_lr = Variable(imgs[\"blur\"].type(Tensor)).to(device)   # torch.Size([4,3,32,32])\n",
        "      imgs_hr = Variable(imgs[\"sharp\"].type(Tensor)).to(device)   # torch.Size([4,3,128,128])\n",
        "      # print('imgs_hr:', len(imgs_hr))\n",
        "\n",
        "      # fake_imgs = netG(imgs_lr)         # 这是一个 batch \n",
        "      # print(len(fake_imgs))\n",
        "      # print(fake_imgs[0][0])\n",
        "      # print(fake_imgs)\n",
        "\n",
        "      # Train discriminator\n",
        "      netD.zero_grad()\n",
        "\n",
        "      real_output = netD(imgs_hr)                               # 清晰的照片->变机率 sigmoid\n",
        "\n",
        "      fake_imgs = netG(imgs_lr)                                 # deblured 的照片, 出来是 Tanh\n",
        "      fake_output1 = netD(fake_imgs.detach())                   # 再丢入discriminator, fake_images.detach()-> 梯度截断，在 backward 不会进行 G.D.\n",
        "\n",
        "      d_loss = discriminator_loss(real_output, fake_output1)\n",
        "      d_loss.backward()\n",
        "      d_optimizer.step()\n",
        "\n",
        "      # Train generator\n",
        "\n",
        "      netG.zero_grad()\n",
        "\n",
        "      fake_output2 = netD(fake_imgs)                 # 这边的W已经跟上面的fake_output不同了，因为上面已经做了 backward, W 已被更新，这个 output 是可以做G.D.的\n",
        "      gen_loss = generator_loss(fake_output2)\n",
        "\n",
        "        # content loss\n",
        "      gen_features = feature_extractor(fake_imgs)\n",
        "      real_features = feature_extractor(imgs_hr)\n",
        "      content_loss = l1_loss(gen_features, real_features.detach())\n",
        "\n",
        "        # total generator loss-> g_loss = gen_loss + content loss\n",
        "      g_loss = content_loss + 1e-3 * gen_loss\n",
        "      g_loss.backward()\n",
        "      g_optimizer.step()\n",
        "\n",
        "  # ------------------------------------------------------------------------------\n",
        "      loss_dis += d_loss.item()         # .item()->to get value\n",
        "      loss_gen += g_loss.item()\n",
        "\n",
        "      d_losses_0106.append(d_loss.item())\n",
        "      g_losses_0106.append(g_loss.item())\n",
        "\n",
        "  # ------------------------------------------------------------------------------\n",
        "      if i % 100 == 0:\n",
        "        sys.stdout.write(\n",
        "                \"[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f]\"\n",
        "                % (epoch, num_epochs, i, len(mini_train), d_loss.item(), g_loss.item())+'\\n'\n",
        "            ) # 相当于print()\n",
        "\n",
        "      batches_done = epoch * len(mini_train) + i\n",
        "      if batches_done % num_iters == 0:\n",
        "        #保存上采样和SRGAN输出的图像\n",
        "        imgs_lr = nn.functional.interpolate(imgs_lr, scale_factor=4)          # 可以是 size=(H,W) or scale_factor\n",
        "        fake_imgs = make_grid(fake_imgs, nrow=1, normalize=True)\n",
        "        imgs_lr = make_grid(imgs_lr, nrow=1, normalize=True)\n",
        "        imgs_hr = make_grid(imgs_hr, nrow=1, normalize=True)\n",
        "        img_grid = torch.cat((imgs_lr, fake_imgs, imgs_hr), -1)            # -1\n",
        "        save_image(img_grid, f\"images_0106/%d.png\" % batches_done, normalize=False)\n",
        "\n",
        "    if epoch % checkpoint_interval == 0:\n",
        "      torch.save(netG.state_dict(), \"saved_models_0106/generator_%d.pth\" % epoch)\n",
        "      torch.save(netD.state_dict(), \"saved_models_0106/discriminator_%d.pth\" % epoch)\n",
        "\n",
        "  end = time.time()\n",
        "  print(f'Total time: {end - start} seconds.')"
      ],
      "metadata": {
        "id": "VLOk5CUasTmg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing"
      ],
      "metadata": {
        "id": "DUexviSgtI8h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if test:\n",
        "\n",
        "  generator_w, discriminator_w = model_checkpoint('Pre_trained_models_by_Jay')    # images 720x1280\n",
        "  # generator_w, discriminator_w = model_checkpoint('saved_models_0107')          # images 288x512\n",
        "  generator_w.sort()\n",
        "  discriminator_w.sort()\n",
        "  # print(len(generator_w))\n",
        "  # print(len(discriminator_w))\n",
        "  # print(generator_w)\n",
        "  # print(discriminator_w)\n",
        "\n",
        "  all_pre_train_dloss_status, all_pre_train_gloss_status = [], []\n",
        "  all_pre_train_hr_lr_p, all_pre_train_hr_fake_p, all_pre_train_lr_fake_p = [], [], []\n",
        "\n",
        "  for j in range(len(generator_w)):\n",
        "\n",
        "    netG.load_state_dict(torch.load(generator_w[j]))\n",
        "    netD.load_state_dict(torch.load(discriminator_w[j]))\n",
        "\n",
        "    locals()['d_losses_test'+str(j)], locals()['g_losses_test'+str(j)] = [], []\n",
        "    p_hr_lr, p_hr_fake, p_lr_fake = [], [], []\n",
        "    l_d, l_g, p_h_l, p_h_f = [], [], [], []\n",
        "\n",
        "    psnr_total1, psnr_total2, psnr_total3 = 0, 0, 0\n",
        "    loss_dis_test, loss_gen_test = 0, 0\n",
        "    dummy1, dummy2, dummy3, dummy4 = 0, 0, 0, 0\n",
        "\n",
        "    start = time.time() \n",
        "    num = 0\n",
        "    for i, imgs in enumerate(mini_test):\n",
        "      netD.eval()\n",
        "      netG.eval()\n",
        "\n",
        "      imgs_lr = Variable(imgs[\"blur\"].type(Tensor)).to(device)   # torch.Size([4,3,32,32])\n",
        "      imgs_hr = Variable(imgs[\"sharp\"].type(Tensor)).to(device)\n",
        "\n",
        "      # Test discriminator\n",
        "      netD.zero_grad()\n",
        "\n",
        "      real_output = netD(imgs_hr)                            \n",
        "\n",
        "      fake_imgs = netG(imgs_lr)                               \n",
        "      fake_output1 = netD(fake_imgs.detach())                 \n",
        "\n",
        "      d_loss = discriminator_loss(real_output, fake_output1)\n",
        "      # d_loss.backward()   # no need to run\n",
        "      # d_optimizer.step()  # no need to run\n",
        "\n",
        "      # Test generator\n",
        "\n",
        "      netG.zero_grad()\n",
        "\n",
        "      fake_output2 = netD(fake_imgs)                 \n",
        "      gen_loss = generator_loss(fake_output2)\n",
        "\n",
        "        # content loss\n",
        "      gen_features = feature_extractor(fake_imgs)\n",
        "      real_features = feature_extractor(imgs_hr)\n",
        "      content_loss = l1_loss(gen_features, real_features.detach())\n",
        "\n",
        "        # total generator loss-> g_loss = gen_loss + content loss\n",
        "      g_loss = content_loss + 1e-3 * gen_loss\n",
        "      # g_loss.backward()   # no need to run\n",
        "      # g_optimizer.step()  # no need to run\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "      loss_dis_test += d_loss.item()\n",
        "      loss_gen_test += g_loss.item()\n",
        "\n",
        "      locals()['d_losses_test'+str(j)].append(d_loss.item())\n",
        "      locals()['g_losses_test'+str(j)].append(g_loss.item())\n",
        "      # print(locals()['d_losses_test'+str(j)])\n",
        "      \n",
        "      dummy1 += d_loss.item()\n",
        "      dummy2 += g_loss.item()\n",
        "      if i % 50 == 0:\n",
        "        d = dummy1/50\n",
        "        g = dummy2/50\n",
        "        l_d.append(d)\n",
        "        l_g.append(g)\n",
        "        dummy1 = 0\n",
        "        dummy2 = 0\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "      imgs_lr = nn.functional.interpolate(imgs_lr, scale_factor=4)\n",
        "    \n",
        "      p1, s1 = PSNR(imgs_hr, imgs_lr)\n",
        "      p2, s2 = PSNR(imgs_hr, fake_imgs)\n",
        "      p3, s3 = PSNR(imgs_lr, fake_imgs)\n",
        "      \n",
        "      p_hr_lr.append(p1)\n",
        "      p_hr_fake.append(p2)\n",
        "      p_lr_fake.append(p3)\n",
        "      # print(p_hr_lr)\n",
        "\n",
        "      dummy3 += p1\n",
        "      dummy4 += p2\n",
        "      if i % 50 == 0:\n",
        "        hl = dummy3/50\n",
        "        hf = dummy4/50\n",
        "        p_h_l.append(hl)\n",
        "        p_h_f.append(hf)\n",
        "        dummy3 = 0\n",
        "        dummy4 = 0\n",
        "# ------------------------------------------------------------------------------\n",
        "      if i % 100 == 0:          # i 是 mini batch 的数量\n",
        "        sys.stdout.write(\n",
        "                \"[Pre train model %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f] [psnr hr_lr: %f] [psnr hr_fake: %f] [psnr lr_fake: %f]\"\n",
        "                % (j, len(generator_w), i, len(mini_test), d_loss.item(), g_loss.item(), p1, p2, p3)+'\\n'\n",
        "            ) # 相当于print()\n",
        "\n",
        "      if i % 100 == 0:\n",
        "        \n",
        "        # imgs_lr = nn.functional.interpolate(imgs_lr, scale_factor=4)          # 可以是 size=(H,W) or scale_factor\n",
        "        fake_imgs = make_grid(fake_imgs, nrow=1, normalize=True)\n",
        "        imgs_lr = make_grid(imgs_lr, nrow=1, normalize=True)\n",
        "        imgs_hr = make_grid(imgs_hr, nrow=1, normalize=True)\n",
        "        img_grid = torch.cat((imgs_lr, fake_imgs, imgs_hr), -1)            # -1\n",
        "        save_image(img_grid, f\"images_test_128X512_all_big/pre_train_model_Jay:{j}_{i} of {len(mini_test)}.png\", normalize=False)\n",
        "\n",
        "    if j & checkpoint_interval == 0:\n",
        "      torch.save(netG.state_dict(), \"saved_models_test_128X512_all_big/generator_%d.pth\" % j)\n",
        "      torch.save(netD.state_dict(), \"saved_models_test_128X512_all_big/discriminator_%d.pth\" % j)\n",
        "\n",
        "    every_pre_train_dw = (sum(locals()['d_losses_test'+str(j)])/len(locals()['d_losses_test'+str(j)]), int(j))\n",
        "    every_pre_train_gw = (sum(locals()['g_losses_test'+str(j)])/len(locals()['g_losses_test'+str(j)]), int(j))\n",
        "\n",
        "    all_pre_train_dloss_status.append(every_pre_train_dw)\n",
        "    all_pre_train_gloss_status.append(every_pre_train_gw)\n",
        "    # print('all_pre_train_dloss_status:', all_pre_train_dloss_status)\n",
        "\n",
        "    every_pre_train_hr_lr_p = (sum(p_hr_lr)/len(p_hr_lr), int(j))\n",
        "    every_pre_train_hr_fake_p = (sum(p_hr_fake)/len(p_hr_fake), int(j))\n",
        "    every_pre_train_lr_fake_p = (sum(p_lr_fake)/len(p_lr_fake), int(j))\n",
        "    \n",
        "    all_pre_train_hr_lr_p.append(every_pre_train_hr_lr_p)\n",
        "    all_pre_train_hr_fake_p.append(every_pre_train_hr_fake_p)\n",
        "    all_pre_train_lr_fake_p.append(every_pre_train_lr_fake_p)\n",
        "    # print('all_pre_train_hr_lr_p:', all_pre_train_hr_lr_p)\n",
        "    \n",
        "    ###### Loss result figure for each pre train model\n",
        "    plt.figure(figsize=(20,5))\n",
        "    ax1 = plt.subplot(1,2,1)\n",
        "    ax2 = plt.subplot(1,2,2)\n",
        "    ax1.set_title('D_loss and G_loss_'+str(j))\n",
        "    ax1.plot(l_d,label='D_loss')                 \n",
        "    ax1.plot(l_g,label='G_loss')\n",
        "    ax1.set_xlabel('Batch')\n",
        "    ax1.set_ylabel('Loss')\n",
        "    ax1.legend()\n",
        "    ###### PSNR figure result for each pre train model                                       \n",
        "    ax2.set_title('PSNR hr_lr X hr_fake_'+str(j))                                    \n",
        "    ax2.plot(p_h_l, label='hr_lr')                                     \n",
        "    ax2.plot(p_h_f, label='hr_fake')\n",
        "    ax2.set_xlabel('Batch')                                                       \n",
        "    ax2.set_ylabel('PSNR')                                                        \n",
        "    ax2.legend()\n",
        "    plt.show()\n",
        "\n",
        "    end = time.time()\n",
        "    print(f'Total time: {end - start} seconds.')"
      ],
      "metadata": {
        "id": "hcnWLCgsssLl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save Losses and PSNR in CSV file"
      ],
      "metadata": {
        "id": "xEU_WiR4eU3n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('losses.csv', 'w') as out:\n",
        "  out.write('d_loss,index_d,g_loss,index_g\\n')\n",
        "  for i in range(len(all_pre_train_dloss_status)):\n",
        "    out.write(str(all_pre_train_dloss_status[i][0])+','+str(all_pre_train_dloss_status[i][1])+','\n",
        "    +(str(all_pre_train_gloss_status[i][0])+','+str(all_pre_train_gloss_status[i][1])+'\\n'))\n",
        "\n",
        "with open('psnr.csv', 'w') as out:\n",
        "  out.write('hr_lr,index,hr_fake,index\\n')\n",
        "  for i in range(len(all_pre_train_hr_lr_p)):\n",
        "    out.write(str(all_pre_train_hr_lr_p[i][0])+','+str(all_pre_train_hr_lr_p[i][1])+','\n",
        "    +(str(all_pre_train_hr_fake_p[i][0])+','+str(all_pre_train_hr_fake_p[i][1])+'\\n'))"
      ],
      "metadata": {
        "id": "kAY_Zgpcu3Zm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('D loss:', all_pre_train_dloss_status)\n",
        "print('******************************************')\n",
        "print('G loss:', all_pre_train_gloss_status)\n",
        "print('*********************************************')\n",
        "print('PSNR hr x lr:', all_pre_train_hr_lr_p)\n",
        "print('***********************************************')\n",
        "print('PSNR hr x fake:', all_pre_train_hr_fake_p)"
      ],
      "metadata": {
        "id": "Ry-Gz3gPu-ei"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Find the best"
      ],
      "metadata": {
        "id": "Uj-RdsHrvEES"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "d_L = all_pre_train_dloss_status\n",
        "g_L = all_pre_train_gloss_status\n",
        "d = max(d_L)\n",
        "print('d loss:', d)\n",
        "g = min(g_L)\n",
        "print('g loss:', g)\n",
        "\n",
        "P1 = all_pre_train_hr_lr_p\n",
        "P2 = all_pre_train_hr_fake_p\n",
        "P3 = all_pre_train_lr_fake_p\n",
        "p1 = max(P1)\n",
        "p2 = max(P2)\n",
        "p3 = max(P3)\n",
        "print('psnr_hr_lr:', p1, 'psnr_hr_fake:', p2, 'psnr_lr_fake:', p3)"
      ],
      "metadata": {
        "id": "bPTgBUrxvHRw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}